{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978eb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TARGET_TZ = ZoneInfo(\"America/Indiana/Indianapolis\")\n",
    "EEG_TEXT_IS_UTC = True           \n",
    "USE_DOMINANT_DAY = False        \n",
    "YEAR_MIN, YEAR_MAX = 2025, 2025\n",
    "\n",
    "HAR_BASE = Path(\"/home/jupyter-yin10/EEG_HAR/data/har_convert\")\n",
    "EEG_BASE = Path(\"/home/jupyter-yin10/EEG_HAR/NEW/data/EEG_25hz_clean\")\n",
    "OUT_BASE = Path(\"/home/jupyter-yin10/EEG_HAR/NEW/data/EEG_Clipped\")\n",
    "SUBJECTS = [f\"s{i}\" for i in range(1, 7)]\n",
    "SAVE_FULL_IF_NO_OVERLAP = True\n",
    "\n",
    "def safe_read_csv(path):\n",
    "    try:\n",
    "        return pd.read_csv(path, dtype=str, encoding=\"utf-8-sig\", na_filter=False)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, dtype=str, encoding=\"utf-8\", na_filter=False)\n",
    "\n",
    "def normalize_text_ts(s):\n",
    "    s = s.astype(str)\n",
    "    s = s.str.replace(\"\\u00A0\", \" \", regex=False)\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    no_sec = s.str.match(r\"^\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}\\s+\\d{1,2}:\\d{2}$\")\n",
    "    s.loc[no_sec] = s.loc[no_sec] + \":00\"\n",
    "    return s\n",
    "\n",
    "def parse_har_local(series):\n",
    "    # HAR strings are local time\n",
    "    s = normalize_text_ts(series)\n",
    "    dt = pd.to_datetime(s, format=\"%Y/%m/%d %H:%M:%S\", errors=\"coerce\")\n",
    "    m = dt.isna()\n",
    "    if m.any():\n",
    "        dt2 = pd.to_datetime(s[m], format=\"%Y-%m-%d %H:%M:%S\", errors=\"coerce\")\n",
    "        dt.loc[m & dt2.notna()] = dt2\n",
    "        m = dt.isna()\n",
    "    if m.any():\n",
    "        dt3 = pd.to_datetime(s[m], errors=\"coerce\")\n",
    "        dt.loc[m] = dt3\n",
    "    dt = dt.dt.tz_localize(TARGET_TZ, nonexistent=\"NaT\", ambiguous=\"NaT\").dt.tz_convert(TARGET_TZ).dt.tz_localize(None)\n",
    "    return dt\n",
    "\n",
    "def parse_eeg_to_local(series):\n",
    "    # EEG may be epoch or text. Epoch is UTC, text interpretation controlled by EEG_TEXT_IS_UTC\n",
    "    s = normalize_text_ts(series)\n",
    "    dt = pd.Series(pd.NaT, index=series.index, dtype=\"datetime64[ns]\")\n",
    "\n",
    "    # epoch first\n",
    "    s_num = pd.to_numeric(series, errors=\"coerce\")\n",
    "    if s_num.notna().any():\n",
    "        med = s_num.dropna().median()\n",
    "        if med >= 1e12:\n",
    "            dt_epoch = pd.to_datetime(s_num, unit=\"ms\", utc=True, errors=\"coerce\")\n",
    "        else:\n",
    "            dt_epoch = pd.to_datetime(s_num, unit=\"s\", utc=True, errors=\"coerce\")\n",
    "        dt.loc[dt.isna()] = dt_epoch.dt.tz_convert(TARGET_TZ).dt.tz_localize(None)\n",
    "\n",
    "    # text, format 1\n",
    "    if dt.notna().mean() < 0.60:\n",
    "        dt_txt = pd.to_datetime(s, format=\"%Y/%m/%d %H:%M:%S\", errors=\"coerce\")\n",
    "        m = dt.isna() & dt_txt.notna()\n",
    "        if EEG_TEXT_IS_UTC:\n",
    "            dt.loc[m] = dt_txt.loc[m].dt.tz_localize(\"UTC\").dt.tz_convert(TARGET_TZ).dt.tz_localize(None)\n",
    "        else:\n",
    "            dt.loc[m] = dt_txt.loc[m].dt.tz_localize(TARGET_TZ).dt.tz_convert(TARGET_TZ).dt.tz_localize(None)\n",
    "\n",
    "    # text, format 2\n",
    "    if dt.notna().mean() < 0.60:\n",
    "        dt_txt2 = pd.to_datetime(s, format=\"%Y-%m-%d %H:%M:%S\", errors=\"coerce\")\n",
    "        m = dt.isna() & dt_txt2.notna()\n",
    "        if EEG_TEXT_IS_UTC:\n",
    "            dt.loc[m] = dt_txt2.loc[m].dt.tz_localize(\"UTC\").dt.tz_convert(TARGET_TZ).dt.tz_localize(None)\n",
    "        else:\n",
    "            dt.loc[m] = dt_txt2.loc[m].dt.tz_localize(TARGET_TZ).dt.tz_convert(TARGET_TZ).dt.tz_localize(None)\n",
    "\n",
    "    # generic text\n",
    "    if dt.notna().mean() < 0.60:\n",
    "        dt_any = pd.to_datetime(s, errors=\"coerce\")\n",
    "        m = dt.isna() & dt_any.notna()\n",
    "        if EEG_TEXT_IS_UTC:\n",
    "            dt.loc[m] = dt_any.loc[m].dt.tz_localize(\"UTC\").dt.tz_convert(TARGET_TZ).dt.tz_localize(None)\n",
    "        else:\n",
    "            dt.loc[m] = dt_any.loc[m].dt.tz_localize(TARGET_TZ).dt.tz_convert(TARGET_TZ).dt.tz_localize(None)\n",
    "\n",
    "    return dt\n",
    "\n",
    "def find_timestamp_column(df):\n",
    "    if \"timestamp\" in df.columns:\n",
    "        return \"timestamp\"\n",
    "    best_col, best_rate = None, -1.0\n",
    "    for col in df.columns:\n",
    "        trial = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "        rate = trial.notna().mean()\n",
    "        if rate > best_rate:\n",
    "            best_rate, best_col = rate, col\n",
    "    return best_col\n",
    "\n",
    "# ---------------------------\n",
    "# Build windows from HAR\n",
    "# ---------------------------\n",
    "def build_windows_from_har(har_dir: Path):\n",
    "    rows = []\n",
    "    for p in sorted(har_dir.glob(\"*.csv\")):\n",
    "        if p.name.startswith(\"har_time_windows_\"):\n",
    "            continue\n",
    "        df = safe_read_csv(p)\n",
    "        if df.shape[1] == 0:\n",
    "            continue\n",
    "        dt = parse_har_local(df.iloc[:, 0])\n",
    "        yr = (dt.dt.year >= YEAR_MIN) & (dt.dt.year <= YEAR_MAX)\n",
    "        dt = dt[yr]\n",
    "        if dt.empty:\n",
    "            continue\n",
    "        if USE_DOMINANT_DAY:\n",
    "            dom = dt.dt.date.value_counts().idxmax()\n",
    "            dt = dt[dt.dt.date == dom]\n",
    "            if dt.empty:\n",
    "                continue\n",
    "        start_raw, end_raw = dt.min(), dt.max()\n",
    "        rows.append({\n",
    "            \"window_id\": len(rows) + 1,\n",
    "            \"har_file\": p.name,\n",
    "            \"start\": start_raw - timedelta(seconds=10),\n",
    "            \"end\": end_raw + timedelta(seconds=10),\n",
    "        })\n",
    "    win_df = pd.DataFrame(rows, columns=[\"window_id\", \"har_file\", \"start\", \"end\"])\n",
    "    if win_df.empty:\n",
    "        raise RuntimeError(f\"No HAR windows built in {har_dir}\")\n",
    "    return win_df.sort_values([\"start\", \"end\"]).reset_index(drop=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Diagnose and clip\n",
    "# ---------------------------\n",
    "def diagnose_and_clip(eeg_dir: Path, out_dir: Path, windows_df: pd.DataFrame, save_full_if_no_overlap: bool = True):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    win = windows_df.copy()\n",
    "    win[\"start\"] = pd.to_datetime(win[\"start\"])\n",
    "    win[\"end\"] = pd.to_datetime(win[\"end\"])\n",
    "\n",
    "    print(\"\\nHAR windows, local time\")\n",
    "    for _, r in win.iterrows():\n",
    "        print(f\"  id {int(r.window_id)}, {r.start} to {r.end}\")\n",
    "\n",
    "    summary_rows = []\n",
    "    for eeg_path in sorted(eeg_dir.glob(\"*.csv\")):\n",
    "        df = safe_read_csv(eeg_path)\n",
    "        before = len(df)\n",
    "        if df.empty:\n",
    "            out = df.iloc[0:0]\n",
    "            out.to_csv(out_dir / f\"{eeg_path.stem}_filtered.csv\", index=False, encoding=\"utf-8\")\n",
    "            summary_rows.append([eeg_path.name, \"EMPTY INPUT\", before, 0, 0.0])\n",
    "            print(f\"{eeg_path.name}: 0.0 percent in window, empty input\")\n",
    "            continue\n",
    "\n",
    "        ts_col = \"timestamp\" if \"timestamp\" in df.columns else find_timestamp_column(df)\n",
    "        if ts_col is None:\n",
    "            if save_full_if_no_overlap:\n",
    "                df.to_csv(out_dir / f\"{eeg_path.stem}_no_overlap_full.csv\", index=False, encoding=\"utf-8\")\n",
    "                summary_rows.append([eeg_path.name, \"NO TIMESTAMP, WROTE FULL FILE\", before, before, 100.0])\n",
    "                print(f\"{eeg_path.name}: 100.0 percent in window, no timestamp column, wrote full file\")\n",
    "            else:\n",
    "                df.iloc[0:0].to_csv(out_dir / f\"{eeg_path.stem}_filtered.csv\", index=False, encoding=\"utf-8\")\n",
    "                summary_rows.append([eeg_path.name, \"NO TIMESTAMP, WROTE EMPTY\", before, 0, 0.0])\n",
    "                print(f\"{eeg_path.name}: 0.0 percent in window, no timestamp column, wrote empty\")\n",
    "            continue\n",
    "\n",
    "        times_local = parse_eeg_to_local(df[ts_col])\n",
    "        if times_local.notna().any():\n",
    "            print(f\"\\nEEG file, {eeg_path.name}\")\n",
    "            print(f\"  EEG local min, {times_local.min()}, EEG local max, {times_local.max()}\")\n",
    "\n",
    "        keep = pd.Series(False, index=df.index)\n",
    "        for _, w in win.iterrows():\n",
    "            in_w = (times_local >= w[\"start\"]) & (times_local <= w[\"end\"])\n",
    "            if in_w.any():\n",
    "                span = times_local[in_w]\n",
    "                print(f\"  Overlap with window {int(w.window_id)}, rows {int(in_w.sum())}, first {span.min()}, last {span.max()}\")\n",
    "            keep |= in_w\n",
    "\n",
    "        if not keep.any():\n",
    "            if save_full_if_no_overlap:\n",
    "                out_name = f\"{eeg_path.stem}_no_overlap_full.csv\"\n",
    "                df.to_csv(out_dir / out_name, index=False, encoding=\"utf-8\")\n",
    "                after = before\n",
    "                pct = 100.0\n",
    "                status = \"NO OVERLAP, WROTE FULL FILE\"\n",
    "            else:\n",
    "                out_name = f\"{eeg_path.stem}_filtered.csv\"\n",
    "                df.iloc[0:0].to_csv(out_dir / out_name, index=False, encoding=\"utf-8\")\n",
    "                after = 0\n",
    "                pct = 0.0\n",
    "                status = \"NO OVERLAP, WROTE EMPTY\"\n",
    "        else:\n",
    "            filtered = df[keep].copy()\n",
    "            out_name = f\"{eeg_path.stem}_filtered.csv\"\n",
    "            filtered.to_csv(out_dir / out_name, index=False, encoding=\"utf-8\")\n",
    "            after = len(filtered)\n",
    "            pct = round(after / max(before, 1) * 100.0, 2)\n",
    "            status = \"OK\"\n",
    "\n",
    "        summary_rows.append([eeg_path.name, status, before, after, pct])\n",
    "        print(f\"{eeg_path.name}: {pct} percent of EEG rows fall inside any HAR window\")\n",
    "        print(f\"  Saved, {out_dir / out_name}\")\n",
    "\n",
    "    sum_df = pd.DataFrame(summary_rows, columns=[\"eeg_file\", \"status\", \"rows_before\", \"rows_after\", \"pct_in_window\"])\n",
    "    sum_csv = out_dir / \"clip_summary.csv\"\n",
    "    sum_df.to_csv(sum_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"\\n[OK] Summary saved, {sum_csv}\")\n",
    "    return sum_df\n",
    "\n",
    "all_summaries = []\n",
    "\n",
    "for subj in SUBJECTS:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"Subject {subj}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    har_dir = HAR_BASE / subj\n",
    "    eeg_dir = EEG_BASE / subj\n",
    "    out_dir = OUT_BASE / subj\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"Building windows from HAR\")\n",
    "    windows = build_windows_from_har(har_dir)\n",
    "\n",
    "    print(\"Clipping EEG with those windows\")\n",
    "    summary = diagnose_and_clip(eeg_dir, out_dir, windows, save_full_if_no_overlap=SAVE_FULL_IF_NO_OVERLAP)\n",
    "\n",
    "    # Tag with subject for later aggregation\n",
    "    summary[\"subject\"] = subj\n",
    "    # Print a compact per subject table\n",
    "    print(\"\\nPer subject summary\")\n",
    "    print(summary[[\"subject\", \"eeg_file\", \"status\", \"rows_before\", \"rows_after\", \"pct_in_window\"]]\n",
    "          .sort_values([\"subject\", \"eeg_file\"])\n",
    "          .to_string(index=False))\n",
    "\n",
    "    all_summaries.append(summary)\n",
    "\n",
    "# Combine all subjects and print a single table\n",
    "combined = pd.concat(all_summaries, ignore_index=True)\n",
    "combined_path = OUT_BASE / \"all_subjects_clip_summary.csv\"\n",
    "combined.to_csv(combined_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\n\" + \"#\" * 70)\n",
    "print(\"Combined summary for all subjects\")\n",
    "print(\"#\" * 70)\n",
    "print(combined[[\"subject\", \"eeg_file\", \"status\", \"rows_before\", \"rows_after\", \"pct_in_window\"]]\n",
    "      .sort_values([\"subject\", \"eeg_file\"])\n",
    "      .to_string(index=False))\n",
    "\n",
    "print(f\"\\nSaved combined summary to {combined_path}\")\n",
    "print(\"\\nOutputs per subject are under:\")\n",
    "for subj in SUBJECTS:\n",
    "    print(f\"  {OUT_BASE / subj}  [filtered clips, no overlap full copies, clip_summary.csv]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12c163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
